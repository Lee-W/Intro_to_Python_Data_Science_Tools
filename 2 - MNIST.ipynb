{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# MNIST\n",
    "[THE MNIST DATABASE of handwritten digits](http://yann.lecun.com/exdb/mnist/)\n",
    "\n",
    "Train classifiers using sklearn to recognize digit images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Table of Content\n",
    "- [Setup](#setup)\n",
    "- [Load Data](#load-data)\n",
    "- [Training](#training)\n",
    "    - [Naive Bayes](#naive-bayes)\n",
    "    - [SVM](#svm)\n",
    "    - [KNN](#knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a name='setup'></a>\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a name='load-data'></a>\n",
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
       " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
       " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
       "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
       "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
       "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
       "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
       "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
       "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
       "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
       "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
       " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 5620\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttp://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\"}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "images = dataset.images\n",
    "labels = dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images.shape:  (1797, 8, 8)\n",
      "labels.shape:  (1797,)\n",
      "First image:\n",
      " [[ 0.  0.  5. 13.  9.  1.  0.  0.]\n",
      " [ 0.  0. 13. 15. 10. 15.  5.  0.]\n",
      " [ 0.  3. 15.  2.  0. 11.  8.  0.]\n",
      " [ 0.  4. 12.  0.  0.  8.  8.  0.]\n",
      " [ 0.  5.  8.  0.  0.  9.  8.  0.]\n",
      " [ 0.  4. 11.  0.  1. 12.  7.  0.]\n",
      " [ 0.  2. 14.  5. 10. 12.  0.  0.]\n",
      " [ 0.  0.  6. 13. 10.  0.  0.  0.]]\n",
      "First label: 0\n"
     ]
    }
   ],
   "source": [
    "print('images.shape: ', images.shape)\n",
    "print('labels.shape: ', labels.shape)\n",
    "print('First image:\\n', images[0])\n",
    "print('First label:', labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images_and_labels = list(zip(images, labels))\n",
    "display_num = 10\n",
    "for index, (image, label) in enumerate(images_and_labels[:display_num]):\n",
    "    plt.subplot(2, math.floor(display_num/2), index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Split training data and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_images = images.reshape((1797, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(flat_images, labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train[0]:  [ 0.  0.  2. 15. 15. 16. 11.  0.  0.  0.  8. 16. 11.  3.  0.  0.  0.  0.\n",
      " 13.  9.  0.  0.  0.  0.  0.  5. 16.  3.  9. 11.  3.  0.  0. 10. 15. 15.\n",
      " 16. 16. 11.  0.  0.  6. 16. 10.  7. 16.  5.  0.  0.  0.  3.  4. 15.  8.\n",
      "  0.  0.  0.  0.  4. 15.  7.  0.  0.  0.]\n",
      "y_train[0]:  5\n"
     ]
    }
   ],
   "source": [
    "print('X_train[0]: ', X_train[0])\n",
    "print('y_train[0]: ', y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a name='training'></a>\n",
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a name='naive-bayes'></a>\n",
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.98 ms, sys: 1.26 ms, total: 4.24 ms\n",
      "Wall time: 3.75 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image:\n",
      " [[ 0.  1. 14. 16. 16. 14.  1.  0.]\n",
      " [ 0.  0. 10. 13.  6.  4.  0.  0.]\n",
      " [ 0.  3. 15. 11.  3.  0.  0.  0.]\n",
      " [ 0.  5. 16. 16. 16.  6.  0.  0.]\n",
      " [ 0.  0.  0.  1. 10. 15.  0.  0.]\n",
      " [ 0.  0.  0.  0. 11. 11.  0.  0.]\n",
      " [ 0.  0.  7. 12. 16.  5.  0.  0.]\n",
      " [ 0.  2. 15. 15.  5.  0.  0.  0.]]\n",
      "Label:  5\n"
     ]
    }
   ],
   "source": [
    "sampled_image_label = random.sample(list(zip(flat_images, labels)), 1)[0]\n",
    "\n",
    "print('Image:\\n', sampled_image_label[0].reshape(8, 8))\n",
    "print('Label: ', sampled_image_label[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict Value:  5\n",
      "Expected Value:  5\n"
     ]
    }
   ],
   "source": [
    "predict_value = clf.predict(sampled_image_label[0].reshape(1, -1))\n",
    "\n",
    "print('Predict Value: ', predict_value[0])\n",
    "print('Expected Value: ', sampled_image_label[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8555555555555555"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = clf.predict(X_test)\n",
    "accuracy_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference\n",
    "[1.9. Naive Bayes](http://scikit-learn.org/stable/modules/naive_bayes.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a name='svm'></a>\n",
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.3 ms, sys: 1.82 ms, total: 35.1 ms\n",
      "Wall time: 36.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9822222222222222"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = clf.predict(X_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Deploy an RBF Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 62.8 ms, sys: 1.8 ms, total: 64.6 ms\n",
      "Wall time: 63.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clf = svm.SVC(kernel='rbf', C=1000, gamma='scale')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9888888888888889"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = clf.predict(X_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Find the best parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = svm.SVC()\n",
    "parameters = {\n",
    "    'kernel': ('linear', 'poly', 'rbf', 'sigmoid'),\n",
    "    'C': (1, 10, 100),\n",
    "    'gamma': ('scale',)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.56 s, sys: 19.5 ms, total: 4.58 s\n",
      "Wall time: 4.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clf = GridSearchCV(svc, parameters, cv=5)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9888888888888889"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = clf.predict(X_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference\n",
    "- [1.4. Support Vector Machine](http://scikit-learn.org/stable/modules/svm.html)\n",
    "- [sklearn.model_selection.GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a name='knn'></a>\n",
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.34 ms, sys: 1.44 ms, total: 3.78 ms\n",
      "Wall time: 4.37 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9933333333333333"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = clf.predict(X_test)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Reference\n",
    "[1.6. Nearest Neighbors](http://scikit-learn.org/stable/modules/neighbors.html)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "livereveal": {
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
